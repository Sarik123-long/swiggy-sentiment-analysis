{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cRX5OJrc8IXo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('swiggydataset.csv.xlsx')\n",
        "print(\"Columns in the dataset:\")\n",
        "print(data.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjGsIRTH8KgT",
        "outputId": "5eb493d9-ca21-49b1-8522-0a69321e221b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in the dataset:\n",
            "['date', 'favorite_count', 'followers_count', 'friends_count', 'full_text', 'retweet_count', 'retweeted', 'screen_name', 'tweet_id', 'user_id']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"full_text\"] = data[\"full_text\"].str.lower()\n",
        "data[\"full_text\"] = data[\"full_text\"].replace(r'[^a-z0-9\\s]', '', regex=True)\n",
        "\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "n3XBcFU38RmJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 5000\n",
        "max_length = 200\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(data[\"full_text\"])\n",
        "X = pad_sequences(tokenizer.texts_to_sequences(data[\"full_text\"]), maxlen=max_length)\n",
        "y = data['friends_count'].values"
      ],
      "metadata": {
        "id": "wdUq83iP9sa8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explicitly define y - NOTE: 'friends_count' is likely NOT the correct\n",
        "# target variable for sentiment analysis. Replace with your actual\n",
        "# sentiment label column if you have one.\n",
        "y = data['friends_count'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "sR1l_tbH9v37"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=max_features, output_dim=16, input_length=max_length),\n",
        "    SimpleRNN(64, activation='tanh', return_sequences=False),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDjcVti--Dl8",
        "outputId": "3e8d8e86-4533-4d8e-b889-50bf2db798c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {score[1]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi0nMvNc-rdH",
        "outputId": "2d337e19-2aa9-48cb-d40e-ec27a1c729be"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.0087 - loss: -2847.0391 - val_accuracy: 0.0139 - val_loss: -8291.2734\n",
            "Epoch 2/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 52ms/step - accuracy: 0.0076 - loss: -11106.0010 - val_accuracy: 0.0139 - val_loss: -14139.4873\n",
            "Epoch 3/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 66ms/step - accuracy: 0.0071 - loss: -18386.8633 - val_accuracy: 0.0139 - val_loss: -19843.2051\n",
            "Epoch 4/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 52ms/step - accuracy: 0.0089 - loss: -23541.6484 - val_accuracy: 0.0139 - val_loss: -25534.0703\n",
            "Epoch 5/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.0086 - loss: -27294.9609 - val_accuracy: 0.0139 - val_loss: -31357.2207\n",
            "Test accuracy: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(review_text):\n",
        "    text = review_text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(seq, maxlen=max_length)\n",
        "\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "    return f\"{'Positive' if prediction >= 0.5 else 'Negative'} (Probability: {prediction:.2f})\"\n",
        "\n",
        "sample_review = \"The food was great.\"\n",
        "print(f\"Review: {sample_review}\")\n",
        "print(f\"Sentiment: {predict_sentiment(sample_review)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDVA528w-xGb",
        "outputId": "acf95467-61f3-404f-cb2a-74e7738a2db5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: The food was great.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "Sentiment: Positive (Probability: 1.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    \"The food was great.\",\n",
        "    \"I will never eat here again.\",\n",
        "    \"Service was slow but the food was tasty.\",\n",
        "    \"Absolutely loved the experience!\",\n",
        "    \"Worst pizza I’ve ever had.\"\n",
        "]\n",
        "\n",
        "for review in reviews:\n",
        "    # Tokenize and pad the review text\n",
        "    seq = tokenizer.texts_to_sequences([review.lower()]) # Convert to lowercase before tokenizing\n",
        "    padded = pad_sequences(seq, maxlen=max_length)\n",
        "\n",
        "    # Predict using the model\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "\n",
        "    # Determine sentiment based on probability\n",
        "    sentiment = \"Positive\" if prediction >= 0.5 else \"Negative\"\n",
        "    probability = prediction if sentiment == \"Positive\" else 1 - prediction\n",
        "\n",
        "    print(f\"Review: {review}\\nSentiment: {sentiment} (Probability: {prediction:.2f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZ0ZRqbJ_P7z",
        "outputId": "da51729b-9a5c-42cd-c6b4-07e85ad203a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Review: The food was great.\n",
            "Sentiment: Positive (Probability: 1.00)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Review: I will never eat here again.\n",
            "Sentiment: Positive (Probability: 1.00)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Review: Service was slow but the food was tasty.\n",
            "Sentiment: Positive (Probability: 1.00)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Review: Absolutely loved the experience!\n",
            "Sentiment: Positive (Probability: 1.00)\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Review: Worst pizza I’ve ever had.\n",
            "Sentiment: Positive (Probability: 1.00)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "vocab_size = 10000  # adjust to your dataset\n",
        "max_length = 100    # max review length\n",
        "embedding_dim = 100\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYygHm4k_mOK",
        "outputId": "4ae8f6fb-29e1-4574-de05-e2874745ec42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 279ms/step - accuracy: 0.0073 - loss: -7471.5864 - val_accuracy: 0.0070 - val_loss: -17725.1406\n",
            "Epoch 2/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 283ms/step - accuracy: 0.0078 - loss: -21699.0508 - val_accuracy: 0.0070 - val_loss: -28816.4004\n",
            "Epoch 3/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 285ms/step - accuracy: 0.0089 - loss: -36353.7617 - val_accuracy: 0.0070 - val_loss: -39036.3750\n",
            "Epoch 4/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 276ms/step - accuracy: 0.0079 - loss: -47751.3711 - val_accuracy: 0.0070 - val_loss: -49208.1211\n",
            "Epoch 5/5\n",
            "\u001b[1m324/324\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 267ms/step - accuracy: 0.0075 - loss: -61291.0430 - val_accuracy: 0.0070 - val_loss: -59343.3008\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ab7a51a6b50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    Conv1D(128, 5, activation='relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "s-aAQ3dh_8RJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "print(classifier(\"The food was great!\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMtWQYnxCFa7",
        "outputId": "6390b398-7f5c-42e8-d4ce-d2f6ced80674"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9998713731765747}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [classifier(text)[0]['label'] for text in reviews]\n"
      ],
      "metadata": {
        "id": "zJK5raqmCJC4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "10W3Dsf3H7b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36753144"
      },
      "source": [
        "!pip install -q gradio"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "3c0c2e41",
        "outputId": "5dece67e-e1ae-4a88-cbcf-c093a8f873f1"
      },
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "# Re-define the sentiment analysis pipeline if the previous cell output is not available\n",
        "# classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def classify_sentiment(text):\n",
        "    # Use the existing classifier pipeline\n",
        "    result = classifier(text)[0]\n",
        "    return f\"{result['label']} (Score: {result['score']:.2f})\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=classify_sentiment,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter text for sentiment analysis...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Sentiment Analysis\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://aa5c99a00a2f7b98f4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aa5c99a00a2f7b98f4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}